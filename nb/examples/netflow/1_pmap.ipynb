{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "GALAXY = 'm31'\n",
    "GALAXYFULLNAME = 'm31'\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "CUT_NB = True\n",
    "KEEP_BLUE = False\n",
    "\n",
    "DATA_DIR = os.environ['PFS_DATA_DIR']\n",
    "\n",
    "OBS_PATH = f'{DATA_DIR}/data/cmdfit/m31/M31Catalog_forPFS.csv'\n",
    "\n",
    "# SIM_PATH = '/datascope/subaru/user/dobos/cmdfit/run/fornax/sim/mix_bin_250k_001/sample.h5'\n",
    "# SIM_PATH = f'{DATA_DIR}/data/cmdfit/run/scl/sim/mix_bin_100k_5/sample.h5'\n",
    "SIM_PATH = f'{DATA_DIR}/data/cmdfit/run/m31/sim/nobin_chab_250k_001/sample.h5'\n",
    "\n",
    "OUTPUT_PATH = f'{DATA_DIR}/data/targeting/{GALAXYFULLNAME}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the probability map\n",
    "\n",
    "Load a CMD simulation, merge foreground and member stellar populations and generate probability map. The script also updates the population weights to match the data.\n",
    "\n",
    "The simulation contain an equal number of stars for each population and vector of population weights. An indicator variable is also generated based on the weights to select a random sample from the simulated stars that follows the population weights. The probability map is calculated from all stars and weighted by the population weights.\n",
    "\n",
    "The population weights of the MW foreground come from Galaxia but they often seem off. Until the population parameters can be automatically estimated by the Bayesian code, we update these weights to better match the observed CMD. This is done by eye.\n",
    "\n",
    "Each population can consist of two sub-populations: single stars and binary stars. If we are only interested in the dSph membership, and the dSph is modeled as a mixture of multiple populations, all sub-populations belonging to the dSph should be merged. The simulations are configured such a way that the dSph member populations are always at the end when ordered by index but their number can vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.patches import Ellipse, Circle\n",
    "from scipy.special import logsumexp\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=6) #controls default text size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG and 'debug' not in globals():\n",
    "    import debugpy\n",
    "    debugpy.listen(('0.0.0.0', int(os.environ['PFS_TARGETING_DEBUGPORT'])))\n",
    "    debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pfs.utils\n",
    "from pfs.ga.targeting.targets.m31 import *\n",
    "from pfs.ga.targeting.instrument import *\n",
    "from pfs.ga.targeting.diagram import CMD, CCD, FOV, FP, ColorAxis, MagnitudeAxis\n",
    "from pfs.ga.targeting.photometry import Photometry, Magnitude, Color\n",
    "from pfs.ga.targeting.projection import WcsProjection, Pointing\n",
    "from pfs.ga.targeting.netflow import Netflow\n",
    "from pfs.ga.targeting.io import DataFrameSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy = GALAXIES[GALAXY]\n",
    "hsc = galaxy.get_photometry()\n",
    "cmd = galaxy.get_cmd()\n",
    "ccd = galaxy.get_ccd()\n",
    "gaia_cmd = galaxy.get_cmd(Gaia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = SubaruHSC.text_observation_reader_m31().read(OBS_PATH)\n",
    "obs.data['targetid'] = np.arange(len(obs.data))+1\n",
    "obs.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the observations\n",
    "\n",
    "f, axs = plt.subplots(1, 2, figsize=(6, 4), dpi=120)\n",
    "\n",
    "cmd.plot_catalog(axs[0], obs, observed=True)\n",
    "ccd.plot_catalog(axs[1], obs, observed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfs.ga.targeting.io import Hdf5SimulationReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Hdf5SimulationReader()\n",
    "cm = {}\n",
    "\n",
    "# Include this for loop for simulations made with older isochrone tables that have different column names\n",
    "for prefix in ['', 'obs_', 'err_', 'flux_', 'obs_flux_', 'err_flux_', 'counts_', 'obs_counts_', 'err_counts_']:\n",
    "    cm[prefix + 'hsc_g2'] = prefix + 'hsc_g'\n",
    "    cm[prefix + 'hsc_i2'] = prefix + 'hsc_i'\n",
    "\n",
    "r.column_mapping = cm\n",
    "r.append_photometry(SubaruHSC.photometry())\n",
    "sim = r.read(SIM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sim.data.keys():\n",
    "    print(k, sim.data[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.s_[::10]\n",
    "\n",
    "f, axs = plt.subplots(1, 2, figsize=(6, 4), dpi=120)\n",
    "\n",
    "cmd.plot_simulation(axs[0], sim, s=s, size=0.05)\n",
    "ccd.plot_simulation(axs[1], sim, s=s, size=0.05)\n",
    "\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply selections\n",
    "\n",
    "Apply the color and magnitude cuts defined in the galaxy class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfs.ga.targeting import ProbabilityMap\n",
    "from pfs.ga.targeting.selection import ProbabilityCut, ProbabilitySampling, MagnitudeSelection, ColorSelection, LinearSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the observations\n",
    "\n",
    "mask = galaxy.get_selection_mask(obs, observed=True, nb=CUT_NB, blue=KEEP_BLUE)\n",
    "\n",
    "f, axs = plt.subplots(1, 2, figsize=(6, 4), dpi=120)\n",
    "\n",
    "cmd.plot_catalog(axs[0], obs, observed=True)\n",
    "cmd.plot_catalog(axs[1], obs, observed=True, mask=mask)\n",
    "\n",
    "f, axs = plt.subplots(1, 2, figsize=(6, 4), dpi=120)\n",
    "\n",
    "ccd.plot_catalog(axs[0], obs, observed=True)\n",
    "ccd.plot_catalog(axs[1], obs, observed=True, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the simulations\n",
    "\n",
    "mask = galaxy.get_selection_mask(sim, observed=True, nb=CUT_NB, blue=KEEP_BLUE)\n",
    "print(mask.shape)\n",
    "\n",
    "f, axs = plt.subplots(1, 2, figsize=(6, 4), dpi=120)\n",
    "\n",
    "cmd.plot_catalog(axs[0], sim, observed=True)\n",
    "cmd.plot_catalog(axs[1], sim, observed=True, mask=mask)\n",
    "\n",
    "f, axs = plt.subplots(1, 2, figsize=(6, 4), dpi=120)\n",
    "\n",
    "ccd.plot_catalog(axs[0], sim, observed=True)\n",
    "ccd.plot_catalog(axs[1], sim, observed=True, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update the population weights\n",
    "\n",
    "This is basically just manually scaling the Galaxia MW population weights until it \n",
    "matches the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for Ursa Minor\n",
    "if GALAXY == 'umi':\n",
    "    # Original weights\n",
    "    print('data.w', sim.data['w'])\n",
    "\n",
    "    w = np.bincount(sim.data['g']) / sim.data['g'].shape\n",
    "    print('w', w, np.sum(w[:-2]), np.sum(w[-2:]))\n",
    "\n",
    "    # New weights, boost thick disk and halo\n",
    "    w1 = np.r_[w[:-2] / 0.4 * 0.5, w[-2:] / 0.6 * 0.5]\n",
    "    w1[2:4] *= 100\n",
    "    # w1[0:6] *= 3  # thin disk 1-3\n",
    "    # w1[4:6] *= 1.2  # thin disk 3\n",
    "    w1[6:8] *= 15  # thick disk\n",
    "    w1[8:10] *= 28   # halo\n",
    "    ##### good for histograms w1[10:12] *= 18  # dSph\n",
    "    ##### good for ghost plot\n",
    "    w1[10:12] *= 50  # dSph\n",
    "    w1 /= w1.sum()\n",
    "    print('w1', w1, np.sum(w1[:-2]), np.sum(w1[-2:]))\n",
    "\n",
    "    # New categories\n",
    "    g1 = np.random.choice(np.arange(w1.size, dtype=int), sim.data['g'].size, p=w1)\n",
    "    print('g1', g1.shape)\n",
    "\n",
    "    # Verify new categories\n",
    "    w2 = np.bincount(g1) / g1.shape\n",
    "    print('w2', w2, np.sum(w2[:-2]), np.sum(w2[-2:]))\n",
    "elif GALAXY == 'fornax':\n",
    "    # Original weights\n",
    "    print('data.w', sim.data['w'])\n",
    "\n",
    "    w = np.bincount(sim.data['g']) / sim.data['g'].shape\n",
    "    print('w', w.shape, w, np.sum(w[:-2]), np.sum(w[-2:]))\n",
    "\n",
    "    w1 = w.copy()\n",
    "    w1[:-6] * 0.7       # MW foreground\n",
    "    w1[-6:-4] *= 2.0    # broad RGB population\n",
    "    w1[-4:-2] *= 0.3    # old RGB population\n",
    "    w1[-2:] *= 1.0      # member MS population\n",
    "    w1 /= w1.sum()\n",
    "\n",
    "    g1 = np.random.choice(np.arange(w1.size, dtype=int), sim.data['g'].size, p=w1)\n",
    "    print('g1', g1.shape)\n",
    "\n",
    "    # Verify new categories\n",
    "    w2 = np.bincount(g1) / g1.shape\n",
    "    print('w2', w2.shape, w2, np.sum(w2[:-2]), np.sum(w2[-2:]))\n",
    "else:\n",
    "    w = np.bincount(sim.data['g']) / sim.data['g'].shape\n",
    "    print('w', w.shape, w, np.sum(w[:-2]), np.sum(w[-2:]))\n",
    "    w1 = w.copy()\n",
    "    g1 = np.random.choice(np.arange(w1.size, dtype=int), sim.data['g'].size, p=w1)\n",
    "    print('g1', g1.shape)\n",
    "    w2 = np.bincount(g1) / g1.shape\n",
    "    print('w2', w2.shape, w2, np.sum(w2[:-2]), np.sum(w2[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of objects inside cuts\n",
    "mask = galaxy.get_selection_mask(obs, nb=CUT_NB, blue=KEEP_BLUE, observed=True)\n",
    "n_obs = mask.sum()\n",
    "print('obs', n_obs)\n",
    "\n",
    "mask = galaxy.get_selection_mask(sim, nb=CUT_NB, blue=KEEP_BLUE, observed=True)\n",
    "mask = sim.apply_categories(mask, g=g1)\n",
    "n_sim = mask.sum()\n",
    "print('sim', n_sim)\n",
    "\n",
    "n_sim / n_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(2, 3, figsize=(6, 6), dpi=120)\n",
    "\n",
    "s = np.s_[::1]\n",
    "\n",
    "mask = galaxy.get_selection_mask(obs, nb=CUT_NB, blue=KEEP_BLUE, observed=True)\n",
    "cmd.plot_observation(axs[0, 0], obs, size=0.05, mask=mask, s=s)\n",
    "ccd.plot_observation(axs[1, 0], obs, size=0.05, mask=mask, s=s)\n",
    "axs[0, 0].set_title('OBS')\n",
    "\n",
    "s = np.s_[::3]\n",
    "\n",
    "mask = galaxy.get_selection_mask(sim, nb=CUT_NB, blue=KEEP_BLUE, observed=True)\n",
    "# mask = sim.apply_categories(mask, g=g1)\n",
    "cmd.plot_simulation(axs[0, 1], sim, observed=True, apply_categories=True, mask=mask, g=g1, s=s, size=0.05)\n",
    "ccd.plot_simulation(axs[1, 1], sim, observed=True, apply_categories=True, mask=mask, g=g1, s=s, size=0.05)\n",
    "axs[0, 1].set_title('SIM updated weights')\n",
    "\n",
    "mask = galaxy.get_selection_mask(sim, nb=CUT_NB, blue=KEEP_BLUE, observed=True)\n",
    "# mask = sim.apply_categories(mask, g=sim.data['g'])\n",
    "cmd.plot_simulation(axs[0, 2], sim, observed=True, apply_categories=True, mask=mask, g=sim.data['g'], s=s, size=0.05)\n",
    "ccd.plot_simulation(axs[1, 2], sim, observed=True, apply_categories=True, mask=mask, g=sim.data['g'], s=s, size=0.05)\n",
    "axs[0, 2].set_title('SIM original weights')\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.grid()\n",
    "    ax.set_xlim(-1, 2.2)\n",
    "\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot color histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(ax, obs, sim, axis, bins, plot_populations=True):\n",
    "    ((x, x_err),) = obs.get_diagram_values([axis], observed=True)\n",
    "    mask = galaxy.get_selection_mask(obs, nb=CUT_NB, blue=KEEP_BLUE, observed=True)\n",
    "    hist, bins = np.histogram(x[mask], bins=bins, density=True)\n",
    "    ax.step(0.5 * (bins[1:] + bins[:-1]), hist, lw=1, label='OBS')\n",
    "    print(x.min(), x.max())\n",
    "\n",
    "    ((x, x_err),) = sim.get_diagram_values([axis], observed=True)\n",
    "    mask = galaxy.get_selection_mask(sim, nb=CUT_NB, blue=KEEP_BLUE, observed=True)\n",
    "    mask = sim.apply_categories(mask, g=g1)\n",
    "    x = sim.apply_categories(x, g=g1)\n",
    "    hist, bins = np.histogram(x[mask], bins=bins, density=True)\n",
    "    ax.step(0.5 * (bins[1:] + bins[:-1]), hist, lw=1, label='SIM')\n",
    "    \n",
    "    if plot_populations:\n",
    "        for i, name in enumerate(['thin1', 'thin2', 'thin3', 'thick', 'halo', 'dSph']):\n",
    "        # for i, name in enumerate(['thin1', 'thin2', 'thin3', 'thick', 'halo', 'dSph1', 'dSph2', 'dSph3']):\n",
    "            hist, bins = np.histogram(x[mask][(g1[mask[:,0]] == 2 * i) | (g1[mask[:,0]] == 2 * i + 1)], bins=bins, density=True)\n",
    "            ax.step(0.5 * (bins[1:] + bins[:-1]), (w1[2 * i] + w1[2 * i + 1]) * hist, lw=0.5, label=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(3.5, 2.4), dpi=240)\n",
    "\n",
    "plot_histogram(ax, obs, sim, cmd.axes[0], bins=np.linspace(-1.0, 2.0, 100))\n",
    "\n",
    "ax.set_xlim(-1, 2.2)\n",
    "ax.set_xlabel('HSC $g - i$')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(3.5, 2.4), dpi=240)\n",
    "\n",
    "plot_histogram(ax, obs, sim, cmd.axes[1], bins=np.linspace(16, 23, 100))\n",
    "\n",
    "ax.set_xlabel('HSC $g$')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(3.5, 2.4), dpi=240)\n",
    "\n",
    "plot_histogram(ax, obs, sim, MagnitudeAxis(hsc.magnitudes['i']), bins=np.linspace(16, 24, 100))\n",
    "\n",
    "ax.set_xlabel('HSC $i$')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create probability map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfs.ga.targeting import ProbabilityMap\n",
    "from pfs.ga.targeting.selection import ProbabilityCut, ProbabilitySampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ursa Minor dwarf\n",
    "if GALAXY == 'umi':\n",
    "    # Original weights\n",
    "    print('data.w', sim.data['w'])\n",
    "\n",
    "    w = np.bincount(sim.data['g']) / sim.data['g'].shape\n",
    "    print('w', w, np.sum(w[:-2]), np.sum(w[-2:]))\n",
    "\n",
    "    # New weights, boost thick disk and halo\n",
    "    w1 = np.r_[w[:-2] / 0.4 * 0.5, w[-2:] / 0.6 * 0.5]\n",
    "    w1[2:4] *= 100\n",
    "    # w1[0:6] *= 3  # thin disk 1-3\n",
    "    # w1[4:6] *= 1.2  # thin disk 3\n",
    "    w1[6:8] *= 15  # thick disk\n",
    "    w1[8:10] *= 28   # halo\n",
    "    ##### good for histograms w1[10:12] *= 18  # dSph\n",
    "    ##### good for ghost plot\n",
    "    w1[10:12] *= 50  # dSph\n",
    "    w1 /= w1.sum()\n",
    "    print('w1', w1, np.sum(w1[:-2]), np.sum(w1[-2:]))\n",
    "\n",
    "    # New categories\n",
    "    g1 = np.random.choice(np.arange(w1.size, dtype=int), sim.data['g'].size, p=w1)\n",
    "    print('g1', g1.shape)\n",
    "\n",
    "    # Verify new categories\n",
    "    w2 = np.bincount(g1) / g1.shape\n",
    "    print('w2', w2, np.sum(w2[:-2]), np.sum(w2[-2:]))\n",
    "elif GALAXY == 'fornax':\n",
    "    # Original weights\n",
    "    print('data.w', sim.data['w'])\n",
    "\n",
    "    w = np.bincount(sim.data['g']) / sim.data['g'].shape\n",
    "    print('w', w, np.sum(w[:-2]), np.sum(w[-2:]))\n",
    "\n",
    "    w1 = w.copy()\n",
    "    w1[:-6] * 0.7       # MW foreground\n",
    "    w1[-6:-4] *= 2.0    # broad RGB population\n",
    "    w1[-4:-2] *= 0.3    # old RGB population\n",
    "    w1[-2:] *= 1.0      # member MS population\n",
    "    w1 /= w1.sum()\n",
    "\n",
    "    g1 = np.random.choice(np.arange(w1.size, dtype=int), sim.data['g'].size, p=w1)\n",
    "    print('g1', g1.shape)\n",
    "\n",
    "    # Verify new categories\n",
    "    w2 = np.bincount(g1) / g1.shape\n",
    "    print('w2', w2, np.sum(w2[:-2]), np.sum(w2[-2:]))\n",
    "else:\n",
    "    w = np.bincount(sim.data['g']) / sim.data['g'].shape\n",
    "    print('w', w.shape, w, np.sum(w[:-2]), np.sum(w[-2:]))\n",
    "    w1 = w.copy()\n",
    "    g1 = np.random.choice(np.arange(w1.size, dtype=int), sim.data['g'].size, p=w1)\n",
    "    print('g1', g1.shape)\n",
    "    w2 = np.bincount(g1) / g1.shape\n",
    "    print('w2', w2.shape, w2, np.sum(w2[:-2]), np.sum(w2[-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The simulation has 10 + 2 * N sub-populations (binaries treated separately for each)\n",
    "# 10 is for 5 MW (3 for the thin disk + 1 thick disk + 1 halo)\n",
    "# Merge foreground populations and members + member binaries when creating the map\n",
    "\n",
    "if GALAXY == 'umi':\n",
    "    extents = [[0.1, 2.0], [17.0, 23.5]]\n",
    "elif GALAXY == 'fornax':\n",
    "    extents = [[-0.75, 2.0], [17.0, 23.5]]\n",
    "else:\n",
    "    extents = [[0.1, 2.5], [17.0, 23.5]]\n",
    "\n",
    "mask = galaxy.get_selection_mask(sim, nb=CUT_NB, blue=KEEP_BLUE, observed=True)\n",
    "# mask = sim.apply_categories(mask, g=g1)\n",
    "\n",
    "pmap = ProbabilityMap(cmd.axes)\n",
    "pmap.from_simulation(sim, bins=[100, 100], extents=extents,\n",
    "    merge_list=[np.s_[:5], np.s_[5:]], population_weights=w1, observed=True, mask=mask)\n",
    "pmap.maximum_filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap.extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, 2, figsize=(6, 4), dpi=120)\n",
    "\n",
    "l0 = cmd.plot_probability_map(axs[0], pmap, 0)\n",
    "l1 = cmd.plot_probability_map(axs[1], pmap, 1)\n",
    "\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save probability maps\n",
    "\n",
    "fn = 'pmap'\n",
    "if CUT_NB:\n",
    "    fn += '_nb'\n",
    "if KEEP_BLUE:\n",
    "    fn += '_blue'\n",
    "fn += '.h5'\n",
    "\n",
    "fn = os.path.join(OUTPUT_PATH, fn)\n",
    "pmap.save(fn)\n",
    "\n",
    "fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membership probability based on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_member, mask_member = pmap.lookup_lp_member(obs)\n",
    "\n",
    "lp_member.shape, np.isnan(lp_member).sum(), np.isnan(lp_member[mask_member]).sum(), mask_member.shape, mask_member.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, 2, figsize=(6, 4), dpi=120)\n",
    "\n",
    "cmd.plot_observation(axs[0], obs, c=lp_member[...,0])\n",
    "ccd.plot_observation(axs[1], obs, c=lp_member[...,0])\n",
    "\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfs_ga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}